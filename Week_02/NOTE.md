# 一、散列表
## 1、散列思想
散列表使用的是数组支持按照下标随机访问数据的特性，时间复杂度是 O(1)。所以散列表其实就是数组的一种扩展，由数组演化而来。  
通过散列函数把元素的键值映射为下标，然后将数据存储在数组中对应下标的位置。  
按照键值查询元素时，使用同样的散列函数，将键值转化数组下标，从对应的数组下标的位置取数据。  

## 2、散列函数
hash(key)，其中key表示元素的键值，hash(key)的值表示经过散列函数计算得到的散列值。  
构造散列函数的基本要求：  
* 散列函数计算得到的散列值是一个非负整数；  
* 如果 key1 = key2，那 hash(key1) == hash(key2)；  
* 如果 key1 ≠ key2，那 hash(key1) ≠ hash(key2)。  

## 3、散列冲突
1). 开放寻址法
如果出现了散列冲突，我们就重新探测一个空闲位置，将其插入。  
往散列表中插入数据时，如果某个数据经过散列函数散列之后，存储位置已经被占用了，那就从当前位置开始，依次往后查找，看是否有空闲位置，直到找到为止。  
2). 链表法
在散列表中，每个位置会对应一条链表，所有散列值相同的元素都放到相同槽位对应的链表中。

## 4、如何设计散列函数
* 如何设计散列函数  
* 散列函数生成的值要尽可能随机并且均匀分布  

## 5、解决装载因子过大问题
静态数据集合：根据数据的特点、分布等，设计出完美的、极少冲突的散列函数。  
动态散列表：进行动态扩容，重新申请一个更大的散列表，将数据搬移到这个新散列表中。  
针对散列表的扩容，数据搬移操作比较复杂。因为散列表的大小改变，数据的存储位置也发生改变，所以需要通过散列函数重新计算每个数据的存储位置。  
最好情况下，插入数据的时间复杂度是O(1)。  
最坏情况下，散列表启动扩容，重新申请内存空间，重新计算哈希位置，并且搬移数据，所以时间复杂度是 O(n)。  
均摊情况下，时间复杂度O(1)。

## 6、如何避免低效地扩容？
为了解决一次性扩容耗时过多的情况，可以将扩容操作穿插在插入操作的过程中，分批完成。当装载因子触达阈值之后，只申请新空间，但并不将老的数据搬移到新散列表中。  
当有新数据要插入时，将新数据插入新散列表中，并且从老的散列表中拿出一个数据放入到新散列表。  
为了兼容了新、老散列表中的数据，对于查询操作，先从新散列表中查找，如果没有找到，再去老的散列表中查找。  

## 7、如何选择冲突解决方法？  
1). 开放寻址法  
优点：所有数据都存储在数组中，有效地利用 CPU缓存加快查询速度；序列化起来比较简单。
缺点：需要特殊标记已经删除掉的数据，比较麻烦；所有的数据都存储在一个数组中，冲突的代价更高。  
2). 链表法 
优点：内存的利用率高；对大装载因子的容忍度高。
缺点：比较消耗内存；在内存中不连续，对CPU缓存不友好，影响执行效率。  
可以将链表法中的链表改造为其他高效的动态数据结构，比如跳表、红黑树。  
**基于链表的散列冲突处理方法比较适合存储大对象、大数据量的散列表，而且，比起开放寻址法，它更加灵活，支持更多的优化策略，比如用红黑树代替链表**  

## 8、工业级散列表举例分析  
**1). 初始大小**  
减少动态扩容的次数，提高HashMap的性能。
**2). 装载因子和动态扩容**  
最大装载因子默认是 0.75，当HashMap中元素个数超过 0.75*capacity的时候，就会启动扩容，每次扩容都会扩容为原来的两倍大小。  
**3). 散列冲突解决方法**
HashMap底层采用链表法来解决冲突。  
当链表长度太长（默认超过 8）时，链表就转换为红黑树。
**4)散列函数**
简单高效、分布均匀。

## 9、LRU缓存淘汰算法
1). 如何通过链表实现 LRU 缓存淘汰算法  
维护一个按照访问时间从大到小有序排列的链表结构。  
缓存大小有限，当缓存空间不够，就直接将链表头部的结点删除。  
当要缓存某个数据的时，先在链表中查找这个数据。如果没有找到，则直接将数据放到链表的尾部；如果找到了，就把它移动到链表的尾部。  
因为查找数据需要遍历链表，所以单纯用链表实现的LRU缓存淘汰算法的时间复杂是 O(n)。

2). 一个缓存（cache）系统主要包含3个操作  
* 往缓存中添加一个数据；
* 从缓存中删除一个数据；
* 在缓存中查找一个数据。

3). 如何将将三个操作的时间复杂度将为O(1)
使用双向链表存储数据，链表中的每个结点处理存储数据（data）、前驱指针（prev）、后继指针（next）之外，再新增了一个特殊的字段hnext。  
每个结点会在两条链中。一个链是的双向链表，另一个链是散列表中的拉链。前驱和后继指针是为了将结点串在双向链表中，hnext指针是为了将结点串在散列表的拉链中。

**如何查找一个数据**：通过散列表，在缓存中找到一个数据，将它移动到双向链表的尾部。  
**如何删除一个数据**：通过散列表，在缓存中找到要删除的结点，并将其删除。  
**如何添加一个数据**：先看这个数据是否已经在缓存中。如果已经在其中，就将其移动到双向链表的尾部；如果不在其中，再要看缓存是否已满。如果满了，则将双向链表头部的结点删除，然后再将数据放到链表的尾部；如果未满，就直接将数据放到链表的尾部。

## 10、Redis有序集合
在有序集合中，每个成员对象有两个重要的属性，key（键值）和score（分值）。通过score、key都能来查找数据。  

1). Redis有序集合的操作：
* 添加一个成员对象；
* 按照键值来删除一个成员对象；
* 按照键值来查找一个成员对象；
* 按照分值区间查找数据；
* 按照分值从小到大排序成员变量；

2). 按照分值将成员对象组织成跳表的结构，再按照键值构建一个散列表。

## 11、Java LinkedHashMap
通过双向链表和散列表组合实现，支持按照插入顺序遍历数据，支持按照访问顺序来遍历数据。  
添加数据时，先查找这个键值是否已经存在，若存在，将其删除，并将新数据放到链表的尾部。若不存在，就直接将数据添加到链表的尾部；  

# 二、二叉树与二叉查找数
## 1、树相关概念
1). 父节点、子节点、兄弟节点、根节点、叶子节点  
2). 节点的高度：节点到叶子节点的最长路径（边数）  
3). 节点的深度：根节点到当前节点所经历的边的个数  
4). 节点的层数：节点深度 + 1    
5). 树的高度：根节点的高度  

## 2、二叉树
1). 每个节点最多有两个节点，分别是左子节点和右子节点。  
2). 满二叉树：叶子节点全都在最底层，除了叶子节点之外，每个节点都有左右两个子节点。  
3). 完全二叉树：叶子节点都在最底下两层，最后一层的叶子节点都靠左排列，并且除了最后一层，其他层的节点个数都要达到最大。  

## 3、二叉树的存储
1). 链式存储法：每个节点有三个字段，其中一个存储数据，另外两个是指向左右子节点的指针。  
2). 顺序存储法：根节点存储在下标i=1的位置，左子节点存储在下标2xi位置，右子节点存储在2xi+1位置 的位置。  
3). 完全二叉树用数组存储最节省内存。  

## 4、二叉树的遍历
1). 前序遍历：先访问当前节点，然后再访问左子树，最后访问右子树。  
2). 中序遍历：先访问左子树，然后再访问当前节点，最后访问右子树。  
3). 先访问左子树，然后再访问右子树，最后访问当前节点。  
4). 二叉树的前、中、后序遍历就是一个递归的过程，  掌握递推公式。
5). 每个节点最多会被访问两次，二叉树遍历的时间复杂度为O(n)。

## 5、二叉查找树（二叉搜索树）
1). 要求：在树中的任意一个节点，其左子树中的每个节点的值，都要小于这个节点的值，而右子树节点的值都大于这个节点的值。  
2). 查找：先取根节点，如果它等于要查找的数据，那就返回。  
如果要查找的数据比根节点的值小，那就在左子树中递归查找；  
如果要查找的数据比根节点的值大，那就在右子树中递归查找。  
3). 插入：如果要插入的数据比节点的数据大，并且节点的右子树为空，就将新数据直接插到右子节点的位置；  
如果不为空，就再递归遍历右子树，查找插入位置。  
同理，如果要插入的数据比节点数值小，并且节点的左子树为空，就将新数据插入到左子节点的位置；  
如果不为空，就再递归遍历左子树，查找插入位置。  
4). 删除：如果要删除的节点没有子节点，直接删除；  
如果要删除的节点只有一个子节点，将父节点指向子节点；  
如果要删除的节点有两个子节点，那就找到这个节点的右子树中的最小节点，把它替换到要删除的节点上。然后再删除掉这个最小节点。  
5). 快速地查找最大节点和最小节点、前驱节点和后继节点。  
6). 中序遍历二叉查找树，可以输出有序的数据序列，时间复杂度是 O(n)。  

## 6、支持重复数据的二叉查找树
针对键值相同的情况，有两种解决方案：  
1). 二叉查找树中每一个节点通过链表和支持动态扩容的数组等数据结构，把值相同的数据都存储在同一个节点上。  
2). 在查找插入位置的过程中，如果碰到一个节点的值，与要插入数据的值相同，就将这个要插入的数据放到这个节点的右子树，当作大于这个节点的值来处理；  
查找数据时，遇到值相同的节点之后，继续在右子树中查找，直到遇到叶子节点才停止；  
删除数据时，需要先查找到每个要删除的节点，然后再按删除操作，依次删除。  

## 7、二叉查找树的时间复杂度分析
1). 最坏情况：二叉查找树退化为链表，查找的时间复杂度为O(n)。  
2). 最好情况：二叉查找树是一棵完全二叉树，插入、删除、查找操作的时间复杂度都和树的高度成正比，为O(height)。  
3). 包含n个节点的完全二叉树的高：第K层包含的节点个数是2^(K-1)， 但最后一层的节点个数在1-2^(L-1)之间。  
n的范围为n >= 1+2+4+8+...+2^(L-2)+1 并且 n <= 1+2+4+8+...+2^(L-2) + 2^(L-1) ，可得L的范围为[log2(n+1), log2n +1]。

# 三、堆
## 1、堆
1).要求：完全二叉树；  
每一个节点的值都必须大于等于（或小于等于）其子树中每个节点的值。  
2).大顶堆：每个节点的值都大于等于子树中每个节点值的堆。    
3).小顶堆：每个节点的值都小于等于子树中每个节点值的堆。  

## 2、堆的实现
1). 存储：完全二叉树适合用数组来存储。通过数组的下标，可以找到一个节点的左右子节点和父节点。  
2). 插入元素：从下往上堆化，新插入的节点与父节点对比大小。如果不满足子节点小于等于父节点的大小关系，就互换两个节点。一直重复这个过程，直到父子节点之间满足大小关系。  
3). 删除堆顶元素：从上往下堆化，把最后一个节点放到堆顶，然后利用父子节点对比方法。对于不满足父子节点大小关系的，互换两个节点，并且重复进行这个过程，直到父子节点之间满足大小关系为止。  
4). 时间复杂度：n个节点的完全二叉树，树的高度为log2n。堆化的过程是顺着节点所在路径比较交换的，所以堆化的时间复杂度跟树的高度成正比，为O(logn)。  
插入数据和删除堆顶元素的主要逻辑就是堆化，时间复杂度为O(logn)。  

## 3、基于堆实现排序
堆排序的过程分为两大的步骤，建堆和排序。  
1). 建堆
将数组原地建堆，从第一个非叶子节点开始，从后往前处理数组，并且每个数据都是从上往下堆化。  
建堆操作的时间复杂度：每个节点堆化的时间复杂度是O(logn)
i). 叶子节点不需要堆化，从倒数第二层开始堆化。  
ii). 节点堆化中需要比较和交换的节点个数和当前节点高度k成正比。  
iii). 每层节点个数为：2^(h-1)，将每个非叶子节点的高度求和：  
S1 = 1 * h + 2^1 * (h-1) + 2^2 * (h-2) + ... + 2^k * (h-k) + ... + 2^(h-1) * 1  
以上公式都乘2，可得： 
S2 = 2^1 * h + 2^2 * (h-1) + ... + 2^k * (h-k+1) + ... + 2^(h-1) * 2 + 2^h * 1  
S = S2 - S1 = -h + 2^1 + 2^2 + 2^3 + ... + 2^k + ... + 2^(h-1) + 2^h  
S的后半部分是等差数列，根据求和公式可得：S = -h + (2^h-2) + 2^h = 2^(h+1)-h-2  
因为h=log2n，因此可得：S = O(n)  
建堆的时间复杂度位O(n)  

2). 排序  
按照大顶堆建堆结束，数组中的第一个元素是最大的元素。将它跟最后一个元素交换，然后将剩下n-1个元素重新构建成堆。直到重复只剩下标为1的一个元素为止。  

## 4、堆排序时间复杂度、空间复杂度以及稳定性
1). 堆排序中，只需个别临时存储空间，所以堆排序是原地排序算法。  
2). 堆排序包括建堆和排序两个操作，建堆过程的时间复杂度是O(n)，排序过程的时间复杂度是 O(nlogn)，所以，堆排序整体的时间复杂度是O(nlogn)。  
3). 堆排序不是稳定的排序算法，在排序中，存在将堆的最后一个节点跟堆顶节点互换的操作，所以就有可能改变值相同数据的原始相对顺序。  

## 5、快速排序要比堆排序性能好
1). 堆排序数据访问的方式没有快速排序友好  
快速排序，数据是顺序访问；堆排序，数据是跳着访问。  
对堆顶节点进行堆化，会依次访问数组下标是1,2,4,8的元素，与快速排序部顺序访问不听，这样对 CPU 缓存是不友好的。  

2). 同样的数据，堆排序算法的数据交换次数要多于快速排序  
基于比较的排序算法，排序过程就是由两个比较和交换基本的操作组成的。  
快速排序数据交换的次数不会比逆序度多。  
堆排序的建堆操作会打乱数据原有的相对先后顺序，导致原数据的有序度降低。  
